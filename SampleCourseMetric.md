#### Weighted rating based on hints taken and average student rating: 

A course with high student ratings but low number of hints taken may be too easy, and not stretch the students enough. The expectation should be that most students will need to use the 'hint' function towards the end of the lesson when exercises become harder. 

This would be a reactive measure, as you would need to collect data from the platform and from the students themselves. The data needed would be

- the student ratings for all courses, 
- the amount of students who rated the course versus the amount of students taken the course, 
- the number of hints taken in total, and,
- the number of hints per student. 

Firstly, I would look at the ratings of other courses that run for a similar amount of time than the course in question. For example, if the course is running for 6 months, I would look at the average rating for all courses that run for a similar amount of time. Then I would look at the average number of ratings per course. Is there a correlation between courses with low ratings and fewer ratings? 

If the average rating is low but there are only a few ratings for this course, it could be that the course is still new and the average rating is not necessarily representative of content. Looking into student feedback could reveal that the reasons for the low rating were connection issues, problems with DataCamp's website, or even typos. 




